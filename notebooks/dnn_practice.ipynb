{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "232fb1b1-ea70-4b73-a412-2ac2afd7e279",
   "metadata": {},
   "source": [
    "# Deep Neural Networks (DNN) Practice with Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a147c128-2d6b-4a03-bb67-2ef91febd03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 00:03:07.659247: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 00:03:07.747157: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-07 00:03:07.750171: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-07 00:03:07.750183: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-07 00:03:07.764741: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-07 00:03:08.130168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-07 00:03:08.130216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-07 00:03:08.130220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import tensorflow, keras and the fashion MNIST modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139332a0-817b-45b7-9de6-3ee9e90e25ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset to memory\n",
    "(training_data, training_labels), (test_data, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f42f44-25f9-4d55-8c85-8f2febbd5013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe95eb35120>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhPklEQVR4nO3df2xV9f3H8ddtaS+0tBdK6S8prOWnE+kmg65DGY4G6BInSoy/soAxGFhxQ+Y0XVR0ztSvS5zRMfhng5mIqInAZJOoYEucLROEMBQ7wMrvFkR7b2npD9vz/YPQWQHhc+jtuy3PR3ITeu95cT4cTu+Lw7333YDneZ4AAOhmMdYLAABcmSggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmOhnvYBvam9v19GjR5WUlKRAIGC9HACAI8/zVF9fr6ysLMXEXPg6p8cV0NGjR5WdnW29DADAZTp06JCGDRt2wcd7XAElJSVJOrPw5ORk49UAAFxFIhFlZ2d3PJ9fSNQKaNmyZfrDH/6gmpoa5eXl6YUXXtDkyZMvmjv7327JyckUEAD0Yhd7GSUqb0J45ZVXtGTJEi1dulQffvih8vLyNHPmTB0/fjwauwMA9EJRKaBnn31W8+fP1z333KPvfve7WrFihRISEvTXv/41GrsDAPRCXV5ALS0t2r59uwoLC/+3k5gYFRYWqqKi4pztm5ubFYlEOt0AAH1flxfQ559/rra2NqWnp3e6Pz09XTU1NedsX1paqlAo1HHjHXAAcGUw/yBqSUmJwuFwx+3QoUPWSwIAdIMufxdcamqqYmNjVVtb2+n+2tpaZWRknLN9MBhUMBjs6mUAAHq4Lr8Cio+P18SJE7Vp06aO+9rb27Vp0yYVFBR09e4AAL1UVD4HtGTJEs2dO1c/+MEPNHnyZD333HNqaGjQPffcE43dAQB6oagU0O23364TJ07oscceU01Njb73ve9p48aN57wxAQBw5Qp4nudZL+LrIpGIQqGQwuEwkxAAoBe61Odx83fBAQCuTBQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBEP+sFAD2J53nOmUAgEIWVnKu5udk588knn/jaV15enq+cKz/H208mJqbv/Vvbz3HwK1rneN/7WwEA9AoUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMMIwU+JruGkb6xRdfOGdWrlzpnElISHDO+M3Fx8c7Z0aMGOGc6a7hr1L3DUv1ozsHrLa3t0dle66AAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmGAYKfA13TVIsrKy0jmzYcMG50xOTo5zRpKampqcMw0NDc6ZjIwM58ydd97pnElMTHTOSP4Gn3bXsNSWlhZfOT/ri4uLc9r+UgelcgUEADBBAQEATHR5AT3++OMKBAKdbuPGjevq3QAAermovAZ0zTXX6J133vnfTvrxUhMAoLOoNEO/fv18vbgIALhyROU1oL179yorK0u5ubm6++67dfDgwQtu29zcrEgk0ukGAOj7uryA8vPztWrVKm3cuFHLly9XdXW1brjhBtXX1593+9LSUoVCoY5bdnZ2Vy8JANADdXkBFRUV6bbbbtOECRM0c+ZM/fOf/1RdXZ1effXV825fUlKicDjccTt06FBXLwkA0ANF/d0BgwYN0pgxY7Rv377zPh4MBhUMBqO9DABADxP1zwGdOnVK+/fvV2ZmZrR3BQDoRbq8gB588EGVl5frs88+0/vvv69bbrlFsbGxvsZnAAD6ri7/L7jDhw/rzjvv1MmTJzV06FBdf/31qqys1NChQ7t6VwCAXqzLC2jNmjVd/VsC3SY2NrZb9rNlyxbnzMcff+ycaW1tdc5IUnt7u3Nm9uzZzpmKigrnzKOPPuqcmTJlinNGksaPH++cGTZsmHOmqqrKOfP+++87ZyRp6tSpzpkxY8Y4bX+pw2yZBQcAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBE1H8gHWDB8zxfuUAg4Jz56KOPnDPvvfeecyYUCjlnwuGwc0aSdu7c2S2ZadOmOWfGjh3rnPF7HPz8PR05csQ5Ex8f75y5/vrrnTOS9Kc//ck5s2TJEqftT506dUnbcQUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADAR8PyODY6SSCSiUCikcDis5ORk6+Wgi/Ww0+0cfqZhz5gxwznjZ4K2H36Pd1xcnHMmGAz62perxMRE50xsbKyvfU2ZMsU5M27cOOeMn+O9bt0654wk/ec//3HOHDhwwGn7S30e5woIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACAiX7WC8CVxc+wz55u6NChzpn+/fs7Z5KSkpwzjY2NzhlJamlpcc5EIhHnzIABA5wz9fX1zhm/w0j/8Y9/OGfeeust50xbW5tz5ujRo84ZSbrzzjt95aKBKyAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmGEYKXKaGhgbnjJ/hk34yycnJzhnJ34BVP5k9e/Y4Z/wMFvU8zzkj+Tvmfoay9uvn/lQcE+Pv+uHTTz/1lYsGroAAACYoIACACecC2rJli2666SZlZWUpEAho3bp1nR73PE+PPfaYMjMzNWDAABUWFmrv3r1dtV4AQB/hXEANDQ3Ky8vTsmXLzvv4M888o+eff14rVqzQ1q1blZiYqJkzZ6qpqemyFwsA6DucX/kqKipSUVHReR/zPE/PPfecHnnkEd18882SpBdffFHp6elat26d7rjjjstbLQCgz+jS14Cqq6tVU1OjwsLCjvtCoZDy8/NVUVFx3kxzc7MikUinGwCg7+vSAqqpqZEkpaend7o/PT2947FvKi0tVSgU6rhlZ2d35ZIAAD2U+bvgSkpKFA6HO26HDh2yXhIAoBt0aQFlZGRIkmprazvdX1tb2/HYNwWDQSUnJ3e6AQD6vi4toJycHGVkZGjTpk0d90UiEW3dulUFBQVduSsAQC/n/C64U6dOad++fR1fV1dXa+fOnUpJSdHw4cO1ePFi/f73v9fo0aOVk5OjRx99VFlZWZo9e3ZXrhsA0Ms5F9C2bdt04403dny9ZMkSSdLcuXO1atUqPfTQQ2poaNB9992nuro6XX/99dq4caP69+/fdasGAPR6Ac/vlL4oiUQiCoVCCofDvB7UB/k53fxk/A5qbGlpcc58//vfd874+TMlJiY6Z/x+AHzUqFHOmczMTOfMm2++6ZzJyspyzvj9eMfp06edM4MHD3bOnDx50jkzbtw454wkffnll86ZV155xWn7+vp6jR8//qLP4+bvggMAXJkoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACacfxwDcDkCgYBzpr29PQorOb93333XOXPw4EHnjJ+Jzg0NDc6Z2NhY54wkhcNh54yfydt+fkxLY2OjcyYYDDpnJH/T0f38PR0/ftw5s3TpUueMJH3wwQfOmba2tqhszxUQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAEwwjRbfyM1jU70BNP8aOHeucSUhIcM40Nzc7Z/wcu5gYf//GPHLkiHNmwIABzpnMzEznjJ9j52dAqCTV19c7Z4YOHeqcyc3Ndc6sWLHCOSNJTz/9tHMmJyfHaftIJHJJ23EFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwMQVPYzU87xuy3VXxs/gzkAg4Jzxy+9wzO4yadIk50xSUpJzZuDAgc6ZpqYm54zfv1s/Q0K/+uor54yfIaHBYNA541d8fLxzxs/3oJ9jV1lZ6ZyR/J2v0dKznw0AAH0WBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAE31mGGl7e7tzxu9gzO4c3tnX7N271zmzZs0a58zmzZudM5KUmJjonMnKynLO+Bks2tra6pzp18/ft3hycrJzxs9AzcbGRufMqVOnnDN+v9f9DI314/Tp084Zv2tbvXq1c+a6667zta+L4QoIAGCCAgIAmHAuoC1btuimm25SVlaWAoGA1q1b1+nxefPmKRAIdLrNmjWrq9YLAOgjnAuooaFBeXl5WrZs2QW3mTVrlo4dO9Zxe/nlly9rkQCAvsf5FcqioiIVFRV96zbBYFAZGRm+FwUA6Pui8hpQWVmZ0tLSNHbsWC1cuFAnT5684LbNzc2KRCKdbgCAvq/LC2jWrFl68cUXtWnTJv3f//2fysvLVVRUpLa2tvNuX1paqlAo1HHLzs7u6iUBAHqgLv8c0B133NHx62uvvVYTJkzQyJEjVVZWpunTp5+zfUlJiZYsWdLxdSQSoYQA4AoQ9bdh5+bmKjU1Vfv27Tvv48FgUMnJyZ1uAIC+L+oFdPjwYZ08eVKZmZnR3hUAoBdx/i+4U6dOdbqaqa6u1s6dO5WSkqKUlBQ98cQTmjNnjjIyMrR//3499NBDGjVqlGbOnNmlCwcA9G7OBbRt2zbdeOONHV+fff1m7ty5Wr58uXbt2qW//e1vqqurU1ZWlmbMmKEnn3xSwWCw61YNAOj1Ap7nedaL+LpIJKJQKKRwONynXg/yM2wwHA47Zw4cOOCcOXbsmHNGkl566SXnzAcffOCcSUhIcM5c6F2XF+PnH0p+hmOOGjXKOdPc3Oyc8TP0VPJ3TsTHxztnGhoanDMX+xzi+fj5O5J0zqSXSxEbG+ucGTx4sHOmpaXFOSPJ15u8duzY4bT9pT6PMwsOAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCiy38kt5VPP/3UOVNSUuJrX4cPH3bO1NbWOmfi4uKcM62trc6Z9PR054zkb/pxSkqKc2bAgAHOmfb2dueMJCUlJTlnJkyY4JxZsWKFc6awsNA588UXXzhnJKl///7Omb179/ral6uKigrnTF1dna99jRw50jnjZ4p/fX29c8bPtHxJ+u9//+srFw1cAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDRY4eRtre3Ow2UnD9/vvM+9u/f75yRpH793A+bn8GifoYa+nH69GlfOT/Hwc+wTz9OnDjhK1dVVeWceeqpp5wzCQkJzpknn3zSOTN8+HDnjORvfbfddptzxs+wTz/DNI8cOeKckfwNwm1qanLOtLW1OWf8PKdIUkZGhq9cNHAFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwESPHUZaVlamxMTES95+z549zvvIy8tzzkjSl19+2S2Zmpoa54wfLS0tvnIfffSRc8bP8MnRo0c7ZyKRiHNGkoYNG+acmTFjhnOmoqLCOTNnzhznzGeffeackfwdv8rKSufM3//+d+eMy5Dis/r37++ckaTGxkbnjJ9hpH74GQYsSa2trc4Z1/PhUrfnCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAICJHjuMNDU1VQMHDrzk7ceOHeu8j88//9w5I8lpXWdlZGQ4Z/wMMPUzCNHvcUhPT3fOXH311c6ZcDjsnElKSnLOSHIagHtWfHy8c+ZHP/qRc2bKlCnOmd27dztnJOnEiRPOmWAw6JwZMmRIt+zH7+BOP0NMm5ubnTOxsbHOGc/znDOSv+HDR44ccdr+1KlTl7QdV0AAABMUEADAhFMBlZaWatKkSUpKSlJaWppmz56tqqqqTts0NTWpuLhYQ4YM0cCBAzVnzhzV1tZ26aIBAL2fUwGVl5eruLhYlZWVevvtt9Xa2qoZM2aooaGhY5sHHnhAb7zxhl577TWVl5fr6NGjuvXWW7t84QCA3s3plbmNGzd2+nrVqlVKS0vT9u3bNXXqVIXDYf3lL3/R6tWr9ZOf/ESStHLlSl199dWqrKzUD3/4w65bOQCgV7us14DOvjspJSVFkrR9+3a1traqsLCwY5tx48Zp+PDhF/wRxM3NzYpEIp1uAIC+z3cBtbe3a/HixZoyZYrGjx8vSaqpqVF8fLwGDRrUadv09HTV1NSc9/cpLS1VKBTquGVnZ/tdEgCgF/FdQMXFxdq9e7fWrFlzWQsoKSlROBzuuB06dOiyfj8AQO/g69NZixYt0oYNG7RlyxYNGzas4/6MjAy1tLSorq6u01VQbW3tBT+IGQwGfX2wDADQuzldAXmep0WLFmnt2rXavHmzcnJyOj0+ceJExcXFadOmTR33VVVV6eDBgyooKOiaFQMA+gSnK6Di4mKtXr1a69evV1JSUsfrOqFQSAMGDFAoFNK9996rJUuWKCUlRcnJybr//vtVUFDAO+AAAJ04FdDy5cslSdOmTet0/8qVKzVv3jxJ0h//+EfFxMRozpw5am5u1syZM/XnP/+5SxYLAOg7Ap7fiXZREolEFAqFtGfPHqeBkj//+c+d95WZmemckS590N7XuQ7zk6S0tDTnTCgUcs60trY6Z/zmYmLc3/fi5635fga5Sv4GSba3tztnAoGAc+bkyZPOGT+DcyV/w1z9DNxtbGx0zmRlZTln4uLinDOSvyGmfvZ1+vRp58zBgwedM5K/IaYLFixw2r6xsVHz589XOBxWcnLyBbdjFhwAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwISvn4jaHbKysr51iuo33X333c77ePbZZ50zkjR69GjnzDXXXOOc6d+/v3PGz6TupqYm54wkNTQ0OGf8TP396quvnDMJCQnOGcnfJGM/k61dzu2zcnNznTOxsbHOGcnfFOiWlhbnzNChQ50z4XDYOePne0mSBg8e3C2Z+Ph454yf80GS9uzZ45y56qqrnLa/1OcGroAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYCHie51kv4usikYhCoZDC4bCvgY0udu7c6Sv31FNPOWc+++wz58zw4cOdM4MGDXLO+B1Y2dbW5pzxM7DSzzBSP2uTJD/fDn6Gkfo5Ds3Nzc4Zv4Nm/eS666nEz35GjBgRhZWcn5+/p5gY92uB6upq54wkFRQUOGeWL1/utP2lPo9zBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBEjx1GWldX5zSM1M9AyO70ySefOGd++ctfOmcOHDjgnPniiy+cM5LU3t7unPEzJLS1tdU543fAqp9vh2HDhjln/JyvY8aMcc74PQ4DBw50zvgdAOvKz7GLi4vzta/ExETnjJ/vi5/97GfOmdGjRztnJCk3N9dXzgXDSAEAPRoFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAAT/awXcCGBQKDHDxh1MW7cOOfMW2+9FYWVnOvEiRO+cnV1dc6ZpKQk58zx48edMxkZGc4ZSerXz/1bIiUlxde+gCsdV0AAABMUEADAhFMBlZaWatKkSUpKSlJaWppmz56tqqqqTttMmzat47/Pzt4WLFjQpYsGAPR+TgVUXl6u4uJiVVZW6u2331Zra6tmzJihhoaGTtvNnz9fx44d67g988wzXbpoAEDv5/SK68aNGzt9vWrVKqWlpWn79u2aOnVqx/0JCQm+XwQGAFwZLus1oHA4LOncdwG99NJLSk1N1fjx41VSUqLGxsYL/h7Nzc2KRCKdbgCAvs/327Db29u1ePFiTZkyRePHj++4/6677tKIESOUlZWlXbt26eGHH1ZVVZVef/318/4+paWleuKJJ/wuAwDQSwU8z/P8BBcuXKg333xT7733noYNG3bB7TZv3qzp06dr3759Gjly5DmPNzc3q7m5uePrSCSi7OxshcNhJScn+1kaHPE5oP/hc0DA5YtEIgqFQhd9Hvd1BbRo0SJt2LBBW7Zs+dbykaT8/HxJumABBYNBBYNBP8sAAPRiTgXkeZ7uv/9+rV27VmVlZcrJybloZufOnZKkzMxMXwsEAPRNTgVUXFys1atXa/369UpKSlJNTY0kKRQKacCAAdq/f79Wr16tn/70pxoyZIh27dqlBx54QFOnTtWECROi8gcAAPROTgW0fPlySWc+bPp1K1eu1Lx58xQfH6933nlHzz33nBoaGpSdna05c+bokUce6bIFAwD6Buf/gvs22dnZKi8vv6wFAQCuDD12Gja6z9ChQ7s154oPNQN9E8NIAQAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmOhnvYBv8jxPkhSJRIxXAgDw4+zz99nn8wvpcQVUX18vScrOzjZeCQDgctTX1ysUCl3w8YB3sYrqZu3t7Tp69KiSkpIUCAQ6PRaJRJSdna1Dhw4pOTnZaIX2OA5ncBzO4DicwXE4oyccB8/zVF9fr6ysLMXEXPiVnh53BRQTE6Nhw4Z96zbJyclX9Al2FsfhDI7DGRyHMzgOZ1gfh2+78jmLNyEAAExQQAAAE72qgILBoJYuXapgMGi9FFMchzM4DmdwHM7gOJzRm45Dj3sTAgDgytCrroAAAH0HBQQAMEEBAQBMUEAAABO9poCWLVum73znO+rfv7/y8/P173//23pJ3e7xxx9XIBDodBs3bpz1sqJuy5Ytuummm5SVlaVAIKB169Z1etzzPD322GPKzMzUgAEDVFhYqL1799osNooudhzmzZt3zvkxa9Ysm8VGSWlpqSZNmqSkpCSlpaVp9uzZqqqq6rRNU1OTiouLNWTIEA0cOFBz5sxRbW2t0Yqj41KOw7Rp0845HxYsWGC04vPrFQX0yiuvaMmSJVq6dKk+/PBD5eXlaebMmTp+/Lj10rrdNddco2PHjnXc3nvvPeslRV1DQ4Py8vK0bNmy8z7+zDPP6Pnnn9eKFSu0detWJSYmaubMmWpqaurmlUbXxY6DJM2aNavT+fHyyy934wqjr7y8XMXFxaqsrNTbb7+t1tZWzZgxQw0NDR3bPPDAA3rjjTf02muvqby8XEePHtWtt95quOqudynHQZLmz5/f6Xx45plnjFZ8AV4vMHnyZK+4uLjj67a2Ni8rK8srLS01XFX3W7p0qZeXl2e9DFOSvLVr13Z83d7e7mVkZHh/+MMfOu6rq6vzgsGg9/LLLxussHt88zh4nufNnTvXu/nmm03WY+X48eOeJK+8vNzzvDN/93Fxcd5rr73Wsc2ePXs8SV5FRYXVMqPum8fB8zzvxz/+sferX/3KblGXoMdfAbW0tGj79u0qLCzsuC8mJkaFhYWqqKgwXJmNvXv3KisrS7m5ubr77rt18OBB6yWZqq6uVk1NTafzIxQKKT8//4o8P8rKypSWlqaxY8dq4cKFOnnypPWSoiocDkuSUlJSJEnbt29Xa2trp/Nh3LhxGj58eJ8+H755HM566aWXlJqaqvHjx6ukpESNjY0Wy7ugHjeM9Js+//xztbW1KT09vdP96enp+uSTT4xWZSM/P1+rVq3S2LFjdezYMT3xxBO64YYbtHv3biUlJVkvz0RNTY0knff8OPvYlWLWrFm69dZblZOTo/379+u3v/2tioqKVFFRodjYWOvldbn29nYtXrxYU6ZM0fjx4yWdOR/i4+M1aNCgTtv25fPhfMdBku666y6NGDFCWVlZ2rVrlx5++GFVVVXp9ddfN1xtZz2+gPA/RUVFHb+eMGGC8vPzNWLECL366qu69957DVeGnuCOO+7o+PW1116rCRMmaOTIkSorK9P06dMNVxYdxcXF2r179xXxOui3udBxuO+++zp+fe211yozM1PTp0/X/v37NXLkyO5e5nn1+P+CS01NVWxs7DnvYqmtrVVGRobRqnqGQYMGacyYMdq3b5/1UsycPQc4P86Vm5ur1NTUPnl+LFq0SBs2bNC7777b6ce3ZGRkqKWlRXV1dZ2276vnw4WOw/nk5+dLUo86H3p8AcXHx2vixInatGlTx33t7e3atGmTCgoKDFdm79SpU9q/f78yMzOtl2ImJydHGRkZnc6PSCSirVu3XvHnx+HDh3Xy5Mk+dX54nqdFixZp7dq12rx5s3Jycjo9PnHiRMXFxXU6H6qqqnTw4ME+dT5c7Dicz86dOyWpZ50P1u+CuBRr1qzxgsGgt2rVKu/jjz/27rvvPm/QoEFeTU2N9dK61a9//WuvrKzMq66u9v71r395hYWFXmpqqnf8+HHrpUVVfX29t2PHDm/Hjh2eJO/ZZ5/1duzY4R04cMDzPM97+umnvUGDBnnr16/3du3a5d18881eTk6Od/r0aeOVd61vOw719fXegw8+6FVUVHjV1dXeO++841133XXe6NGjvaamJuuld5mFCxd6oVDIKysr844dO9Zxa2xs7NhmwYIF3vDhw73Nmzd727Zt8woKCryCggLDVXe9ix2Hffv2eb/73e+8bdu2edXV1d769eu93Nxcb+rUqcYr76xXFJDned4LL7zgDR8+3IuPj/cmT57sVVZWWi+p291+++1eZmamFx8f71111VXe7bff7u3bt896WVH37rvvepLOuc2dO9fzvDNvxX700Ue99PR0LxgMetOnT/eqqqpsFx0F33YcGhsbvRkzZnhDhw714uLivBEjRnjz58/vc/9IO9+fX5K3cuXKjm1Onz7t/eIXv/AGDx7sJSQkeLfccot37Ngxu0VHwcWOw8GDB72pU6d6KSkpXjAY9EaNGuX95je/8cLhsO3Cv4EfxwAAMNHjXwMCAPRNFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATPw/ujflcCL66CwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display one of the images from the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 0\n",
    "\n",
    "print(f\"Label: {training_labels[index]}\")\n",
    "\n",
    "plt.imshow(training_data[index], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1659f2-593c-449c-b0d5-2f73cf686cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the images\n",
    "training_data = training_data / 255.0\n",
    "test_data = test_data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d86118-7abb-4336-931a-1dea14e42f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 00:05:28.496219: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-07 00:05:28.496241: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-07 00:05:28.496261: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2022-11-07 00:05:28.496436: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define the AI model\n",
    "model = keras.models.Sequential(\n",
    "    layers=[\n",
    "        keras.layers.Flatten(input_shape=training_data[0].shape),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a00aac-8845-4f63-86ca-52e58a55ce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5033 - accuracy: 0.8242\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3820 - accuracy: 0.8630\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3422 - accuracy: 0.8765\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3165 - accuracy: 0.8840\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2981 - accuracy: 0.8908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe96361f6a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(training_data, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b4f4ff3-2072-463d-a038-9dfe7e713184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 789us/step - loss: 0.3525 - accuracy: 0.8743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35245203971862793, 0.8743000030517578]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd48b7-4c43-4344-afec-5ffbd7704c09",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf09f66-d8b6-4a07-8a13-d44cfdb33f5e",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "For the first exercise, run the below code: It creates a set of classifications for each of the test images, and then prints the first entry in the classification set. The output, after we run it is a list of numbers. Why do you think this is, and what do those numbers represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d38ffa6b-8925-49bb-afea-4c90a66aec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 508us/step\n",
      "[8.8558963e-06 4.1190239e-07 1.9421605e-06 1.6872526e-06 3.2725750e-06\n",
      " 8.0310227e-03 1.9290726e-06 5.2518904e-02 2.4026781e-04 9.3919176e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_data)\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827ab4c-74c7-4be8-8b52-c103c7d2f5d8",
   "metadata": {},
   "source": [
    "The reason why the output is a list of numbers is because each neuron at the output layer produces an output based on the input we want to classify. Since we have 10 neurons, we will have 10 outputs. Each number in this list represents a label. This means that the result we get is a list of probabilities which represents the probability of a given image to belong in a given class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a970ac-a1a7-4c51-9c87-03f81bb9d6db",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Let's now look at the layers in the model. Experiment with different values for the dense layer with 512 neurons. What different results do you get for loss, training time etc.? Why do you think that's the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a4fb127-ce73-4ae2-8ef9-fce2fc0b3d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 910us/step - loss: 0.4760\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3560\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 955us/step - loss: 0.3200\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2981\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 868us/step - loss: 0.2797\n",
      "313/313 [==============================] - 0s 503us/step - loss: 0.3488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34878453612327576"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating another model with a different number of neuron in the hidden layer\n",
    "model_2 = keras.models.Sequential(\n",
    "    layers=[\n",
    "        keras.layers.Flatten(input_shape=training_data[0].shape),\n",
    "        keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_2.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\"\n",
    ")\n",
    "\n",
    "model_2.fit(training_data, training_labels, epochs=5)\n",
    "\n",
    "model_2.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16afa010-42bb-4b06-8500-ab083fb8aedd",
   "metadata": {},
   "source": [
    "Training time seems to be faster when we increased the number of neurons from 128 to 512. Each epoch took 3 seconds when we had 128 neurons in the hidden layer. On the other hand, each epoch took 2 seconds when we had 512 neurons.\n",
    "\n",
    "Loss seems to be hovering around the same value, however it is lower when we have 512 neurons in the hidden layer.\n",
    "\n",
    "The reason why this is the case can be explained as we now have more variables that we use to determine the rules (128 vs 512), which will result in a better estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36457a76-3a4c-4ce6-9076-196472d76a0c",
   "metadata": {},
   "source": [
    "### E2Q1: What happens if we increase the number of neurons in the hidden layer from 512 to 1024?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff12b04-587b-437c-8e57-4eb5321de7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 873us/step - loss: 0.4690\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 847us/step - loss: 0.3576\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 870us/step - loss: 0.3216\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 866us/step - loss: 0.2956\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 855us/step - loss: 0.2759\n",
      "313/313 [==============================] - 0s 539us/step - loss: 0.3293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32926908135414124"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = keras.models.Sequential(\n",
    "    layers=[\n",
    "        keras.layers.Flatten(input_shape=training_data[0].shape),\n",
    "        keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_3.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "model_3.fit(training_data, training_labels, epochs=5)\n",
    "\n",
    "model_3.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220d174-2c1f-4abd-9ed8-4ca529c33fd1",
   "metadata": {},
   "source": [
    "Here, we can see that the training time is around the same when compared to the training times of 128 and 512 neurons. However, the loss at the end of 5 epochs is the lowest out of the 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e93d57-2152-43e2-bc94-465452d2eb35",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "### E3Q1: What would happen if you remove the Flatten() layer? Why do you think that's the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd311323-c80f-448e-ab8e-f00bddb89e83",
   "metadata": {},
   "source": [
    "Removing the flatten layer will result in a runtime error where the shape of hidden layer does not match the shape of the input. The reason why we get this error is that TensorFlow is enforcing the rule of thumb that the first layer in the network should be the same shape as the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9abe1c-d577-41e8-bb24-7b161805eaa2",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Consider the final (output) layers. Why are there 10 of them? What would happen if you had a different amount than 10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b0f8f-1afa-4ff6-b9f6-d77b0be59be0",
   "metadata": {},
   "source": [
    "There are 10 of them because we have 10 labels. If we had a different amount than 10, we would face another runtime error, probably an index error when the model tries to predict a label that is greater than the number of neurons we have.\n",
    "\n",
    "This is another rule of thumb that the number of neurons in the last layer should match the number of classes we are classifying for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc5f8d-3d3d-4b5b-b375-721038c18c84",
   "metadata": {},
   "source": [
    "## Exercise 5:\n",
    "\n",
    "Consider the effects of additional layers in the network. What will happen if you add another layer between the one with 512 and the final layer with 10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e97b5-0753-4c76-a8c7-d4e0b59080c1",
   "metadata": {},
   "source": [
    "In our current exercise, having additional layers wouldn't have much of an impact since we are dealing with relatively simple data. However, for far more complex data, it is often necessary to have extra layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc633f6e-8f01-4874-8bf7-9180ee51bff2",
   "metadata": {},
   "source": [
    "## Exercise 6:\n",
    "\n",
    "### E6Q1: Consider the impact of training for more or less epochs. Why do you think that would be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8ac74-2e6b-4880-a530-5f256ae7fe32",
   "metadata": {},
   "source": [
    "In our example, traning for less epochs would mean that we would have a less accurate model with a higher loss value. However, training for more epochs would mean that we are improving the accuracy of our model.\n",
    "\n",
    "One thing to note is that training the model after a certain number of epochs might cause the model to \"overfit\", which can result in worse accuracy numbers when evaluated using the test data. This is why it is important to find a balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4320fcf0-27e9-43c3-837e-c815d0c098c7",
   "metadata": {},
   "source": [
    "## Exercise 7:\n",
    "\n",
    "Before you trained, you normalized the data, going from values that were 0-255 to values from 0-1. What would be the impact of removing that? Why do you think you get different results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61556f3a-68e7-4dbd-90d7-25c0f74974a0",
   "metadata": {},
   "source": [
    "Since we are dealing with larger floating point numbers, we will be increasing the effect of rounding errors which means that our model will be less accurate due to the rounding errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e15dc-3567-4569-a298-98de84d32216",
   "metadata": {},
   "source": [
    "## Exercise 8:\n",
    "\n",
    "Earlier when you trained for extra epochs, you had an issue where your loss might change. It might have taken a bit of time for you to wait for the training to do that, and you might have thought \"wouldn't it be nice if I could stop the training when I reached a desired value?\" -- i.e. 60% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs... So how would you fix that? Like any other program... you have callbacks! Following is an example on how to implement one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13ffb2c2-1fcd-4ef8-92b7-6a70e06e3677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1838/1875 [============================>.] - ETA: 0s - loss: 0.4768 - accuracy: 0.8308\n",
      "Reached 80% accuracy, stopping training.\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4752 - accuracy: 0.8313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8d85d18a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callback to stop training once we hit the desired accuracy\n",
    "class StopTrainingOnAccuracyCallback(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        if not logs:\n",
    "            logs = {}\n",
    "        \n",
    "        if logs.get(\"accuracy\") >= 0.8:\n",
    "            print(\"\\nReached 80% accuracy, stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = [StopTrainingOnAccuracyCallback()]\n",
    "\n",
    "model_4 = keras.models.Sequential(\n",
    "    layers=[\n",
    "        keras.layers.Flatten(input_shape=training_data[0].shape),\n",
    "        keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_4.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_4.fit(training_data, training_labels, epochs=10, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
